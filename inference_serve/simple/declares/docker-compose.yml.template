version: "3.9"
services:
  inference:
    command: ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
    image: your-registry/your-image-name:latest
    environment:
      - MODEL_PATH=/app/chatglm2-6b
      - TOKENIZER_PATH=/app/chatglm2-6b
    volumes:
      - /data/chatglm2-6b:/app/chatglm2-6b
      - /data/syrax/inference_serve/simple/model.py:/app/model.py
      - /usr/local/lib/python3.10/dist-packages:/usr/local/lib/python3.10/site-packages
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]